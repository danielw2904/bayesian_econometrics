---
title: "Homework"
output: html_notebook
---

I have an iid random sample $Y=(y_1,...y_N)$ with $p(y_i|\theta) = \theta^{y_i}(1-\theta)^{y_i}$ if $0\leq y_i \leq1$ and $0$ otherwise. The prior is 
\begin{equation}
\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1} \quad \text{if} \quad 0 < \theta <1
\end{equation}

and $0$ otherwise.

Now my thinking was the following:

$p(y|\theta) = \Pi_{i=1}^N \theta^{y_i}(1-\theta)^{y_i} = \theta^{\Sigma y_i}(1-\theta)^{\Sigma y_i}$

The posterior is Likelihood times Prior thus:

$p(\theta | y) \propto \theta^{\Sigma y_i}(1-\theta)^{\Sigma y_i} \theta^{\alpha-1}(1-\theta)^{\beta-1} = \theta^{\Sigma y_i +\alpha-1}(1-\theta)^{\Sigma y_i + \beta-1}$

This looks like a (kernel of a?) Beta distribution. 

    
And found that choosing $\alpha = 2,\beta=4$ results approximately in a beta distribution with $\alpha = 2, \beta = 7$. However, according to the calculation above the same number should be added to both parameters. Thus my twofold question: How would I determine $\Sigma_i y_i$ and how would I apply that to the example below?



```{r}
a <- 2
b <- 4

scale <- gamma(a+b) / (gamma(a) * gamma(b))
p_grid<-seq(0,1,length.out = 100)

prior_theta <- function(a,b){
  length_x <- 100
  theta <- seq(0,1,length.out = length_x)
  p_theta <- scale * (theta^(a-1)) * ((1-theta)^(b-1))
  return(p_theta/100)
}

lik_y <- function(ptheta){
  length_y <- 100
  y <- seq(0,1, length.out = length_y)
  p_y <- (ptheta^y)*((1-ptheta)^y)
  return(p_y)
}

theta <- prior_theta(a,b)

prob_y <- lik_y(theta)
prob_y

unstandardized_posterior <- prob_y*theta

standardized_posterior <- unstandardized_posterior/sum(unstandardized_posterior)


post_check <- dbeta(seq(0,1,length.out = 100), 2, 7)/100


plot(standardized_posterior);lines(post_check, col = "red")




```

